{
  "name": "Seniorfieldproject",
  "tagline": "Semester-long research on technology trends and what not.",
  "body": "# Senior Field Project: GC Team\r\n#### A Glance at Trending Technologies - A Senior Field Project by Xi, Xin, Giang\r\nBrandeis, Spring 2016\r\n\r\n## Objectives\r\nModern websites, mobile applications and open source projects are composed of many technologies and services from a variety of vendor. The relative popularity of these components is of interest to both developers and investors. The goal of this project is to research and test several discovery tools. \r\n\r\n## Methodology\r\nWe first came up with a Technology Whitelist that lists out the interesting technologies and their “signatures”. A technology signature can be anything from HTML tags to IP addresses linked to a known service. \r\n\r\nRegarding data sources, we decided to dig deep into three realms: [CommonCrawl](http://commoncrawl.org/), [GitHub](https://github.com/), [Reddit](https://www.reddit.com/) and [HackerNews](https://news.ycombinator.com/). Refer to our linked paper report for the detailed work on each data source. For our demonstration, we narrowed down our search to 5 interesting technologies: Jquery, AngularJs, Ionic, React and Hubspot services. \r\n\r\n## Results\r\nOur final result consists of several graphings demonstrating the use of websites and technologies from CommonCrawl data and allows user to search for repo of interest on GitHub (BONUS: the repo data will also return with a hotness score)\r\n\r\n### Common Crawl\r\nCommonCrawl data provides us with the usage trend of those aforementioned technolgies as well as the top six most active websites in the 18 months of data available. \r\n\r\n#### Technology Usage Trend\r\nClick to see[JQUERY USAGE TREND](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/Jquery%20Trend.pdf)\r\n\r\n#### Technology Usage By Month\r\nClick to see [Dec 2015](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/CommonCrawlData/technologies-graph/012015.pdf)\r\n\r\nUser needs to specify month and year to see the statistics for that month. More can be found in [this folder](https://github.com/GiangNguyen94/SeniorFieldProject/tree/master/CommonCrawlData/technologies-graph)\r\n\r\n#### Website Crawled Visits By Month\r\nClick to see [Dec 2015](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/CommonCrawlData/websites-graph/012015.pdf)\r\n\r\nUser needs to specify month and year to see the statistics for that month.\r\nMore can be found in [this folder](https://github.com/GiangNguyen94/SeniorFieldProject/tree/master/CommonCrawlData/websites-graph)\r\n\r\n### GitHub\r\nHere we show some sample data from GitHub research\r\n\r\n#### Trending: jQuery as an example\r\n* Commit trend of [jQuery](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/commit_trend_for_repo_jquery.pdf)\r\n* Fork trend of [jQuery](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/fork_trend_for_repo_jquery.pdf)\r\n* Issue Event trend of [jQuery](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/issue_trend_for_repo_jquery.pdf)\r\n\r\n#### Scoring: grit as an example\r\n[grit](https://github.com/mojombo/grit) is one of the earliest repo on github.\r\nIt's final score is: 912.166\r\n\r\nHere are the break down:\r\n* Owner's username: [mojombo](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/username.txt)\r\n* Owner's Reddit score: [1.0](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/user_reddit.score)\r\n* Owner's HackerNews score: [3.69](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/user_hackers.score)\r\n* Repo's commit history score: [48.42](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/commit/history.score)\r\n* Repo's fork history score: [21.049](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/fork/history.score)\r\n* Repo's issue event history score: [124.98](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/issue_event/history.score)\r\n\r\nAlso for your reference are:\r\n* Repo's commit history: [this csv](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/commit/grit.csv)\r\n* Repo's fork history: [this.csv](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/fork/grit.csv)\r\n* Repo's issue event history: [this.csv](https://github.com/GiangNguyen94/SeniorFieldProject/blob/master/DemoGraphs/grit-show-scoring/issue_event/grit.csv)\r\n\r\n\r\n\r\n## Code\r\n```\r\nCommon Crawl WARC Examples/                 working example of exploring WARC files\r\nCommonCrawJavaFiles/                        all java files for Common Crawl\r\nGithubLanguage/\r\n    analysis/\r\n        commit_history.py                   gets the commit history\r\n        dbservice.py                        connects to the local database\r\n        fork_history.py                     gets the fork history\r\n        fun_facts.py                        few fun facts about github repos\r\n        get_keys.py                         gathers the attributes returned by github api\r\n        history.py                          wrapper for commit, fork and event history\r\n        issue_event_history.py              gets the issue event history\r\n        language_stats.py                   gathers statistics of language used in repos\r\n        OAuth.py                            prepares github access token\r\n        repo_user.py                        reports users contributed to the repos\r\n        run.py                              interface for shell script's default run\r\n        score.py                            calculates the history scores\r\n        search.py                           searchs for repos\r\n        user_stats.py                       gathers statistics about users\r\n    json_to_sqlites.py                      dumps json's from api calls to sqlite3\r\n    repositories.py                         downloads repo infomation from github\r\n    Shell/\r\n        hackernews.py                       generates the hackernews score\r\n        history_score.py                    reports the history scores\r\n        importPraw.py                       generates the reddit scire\r\n        run.sh                              the main shell script\r\n        RViz.R                              R script to generate trending graphs\r\n\r\n```\r\n\r\n## Architecture & Design\r\n![Flow Chart](https://raw.githubusercontent.com/GiangNguyen94/SeniorFieldProject/master/Report/flowchart.png)\r\n\r\n## Scoring a Github repo\r\nWe found out a relatively smart way to score the open source projects on GitHub. We have the preliminary score which shows first when you search, which is just stars and forks of the repo combined. This pre-score lets us have a quick glance at the repo and once we know which repo we want to see further, the final score is generated. The final score formula is as follows:\r\n( Commit_Score + Fork_Score + Issue_Score ) * ( Reddit_Score + HackerNews_Score) \r\n\r\nWhen we run the GitHub script we have the three history files for commits, forks and issue events. From that we would generate the first three subscores of the formula. A history file tracks the activity of the corresponding type by month. Since we are more interested in the recent technologies, we assign higher weights to more recent months. This results in a geometric weight system that for every month backwards in the past, the value of that month is changed by a multiplier which degenerates monthly as well. We use a 90% multiplier coefficient so the most recent month would be 100% of value, the next ones would be 90%, 81%, 72.9%, … of value. For the Reddit and Hacker News score, we would take the log base 10 of each total karma score of a user from those two sites and then add them together. If the karma score is less than 10 (in case a user does not have an account there), we assign a value of 1 to that score and continue calculating as usual.\r\n\r\n## Installation\r\n* Github API access token\r\n    - Follow the link to aquire your Github API access tokens: <https://help.github.com/articles/creating-an-access-token-for-command-line-use/>\r\n    - Store your access token in `GithubLanguage/analysis/access_token.secret`, one token per line\r\n    - Also copy to `GithubLanguage/access_token.secret` if you wish to run scripts outside of `analysis`\r\n* Bash\r\n* Python 2.7\r\n    * urllib2\r\n    * progressbar\r\n    * ipython\r\n* Python 3.4\r\n    - Use `python3 -m pip install <package>` to specify the python version\r\n    * praw\r\n* R 3.2.4\r\n    * ggplot2\r\n* PDF Viewer\r\n* Internet Access\r\n\r\n## Suggestions for Future Work\r\n#### Common Crawl\r\nIf we had more time, we would try to use the new index and query API system of common crawl. This new feature was made by common crawl community in January 2015, which provides an API that allows user to query a particular index for a particular domain, (index is a snapshot for each crawling run they perform), and it will return back results that point you to the location of where the actual HTML content for that snapshot lives. Moreover probably do some semantic analysis with WET files would also be helpful.\r\n\r\n#### Reddit / HackerNews\r\nFor possible future continuation of this project, we think it would be better to use Reddit / Hacker News to track a particular interest and use other data resources to get the big picture. Stackoverflow, The Internet Archive and other social media services like Facebook, Twitter, Vk, Weibo seem to have a lot of potential for that. Also, we suggest using our methodology but in a much larger scale, handling big data to get all the scores possible and compare them with each other. If possible, we would try to draw correlations and heatmaps of developers’ associated communities.\r\n\r\n#### GitHub\r\nAs suggestions for the future, we can consider more about how to incorporate user’s value into the evaluation of repos. With the history we can find the user connected with each event, and there are repos, other users, and events connect to that user. With some iterations, the evaluation of users and repos may come to a fixed point and that probably will be score we were looking for.\r\n\r\nMore generally, I would say simply with the GitHub data source alone, it would be worthy of a team’s investment. With more manpower, we can dig deeper into the information behind the tons’ of data. Although we did not follow through our attempt with GitHub Archive and Google BigQuery, these still are great data source and still worth look into. As time changes there will be more and more repos on GitHub. New tools and new information may come into light at any time. \r\n\r\n\r\n## Team Members\r\n* [Giang Nguyen](https://github.com/GiangNguyen94) <<giangcoi@brandeis.edu>>\r\n    - Giang is a graduating Senior at Brandeis University.\r\n* [Xi Qian](https://github.com/qxx) <<qxx@brandeis.edu>>\r\n    - Xi is a graduating Master's student at Brandeis Univeristy.\r\n* [Xin Yao](https://github.com/XinYao1992) <<xyao01@brandeis.edu>>\r\n    - Xin is a Master's student at Brandeis University.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}